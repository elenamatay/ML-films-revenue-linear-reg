{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a174fb92-27ed-46a5-8269-25be4d611c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2207d183-3217-4cee-a2df-32c8f6c125f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Gather Data\n",
    "boston_dataset = load_boston()\n",
    "data = pd.DataFrame(data=boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "features = data.drop(['INDUS', 'AGE'], axis=1)\n",
    "\n",
    "log_prices = np.log(boston_dataset.target)\n",
    "target = pd.DataFrame(log_prices, columns=['PRICE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "97a2dddc-abda-4e25-a3bb-3cf728baf935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indexes in order to simplify later access to our data (using unpacking):\n",
    "CRIM_IDX, ZN_IDX, CHAS_IDX, NOX_IDX, RM_IDX, DIS_IDX, RAD_IDX, TAX_IDX, PTRATIO_IDX, B_IDX, LSTAT_IDX =  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee9461-2e35-441c-9afd-c5664396d3d5",
   "metadata": {},
   "source": [
    "As we want to generate predictions of the value of a property, we'll need to create something that looks like another row of data, structured the same way of our features, to store predictions. Let's create a variable for that: property_stats. For the first property we'll evaluate, let's just go with Boston's AVG for all features. mean() returns a pandas Series, we need to take its .values 1D array, then reshape it to 2D to fit it into stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e4c09a85-ff0f-4840-8563-70c8a86f26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_stats = features.mean().values.reshape(1, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d46b06-0956-40b2-a25f-d1c6aa5a7ccc",
   "metadata": {},
   "source": [
    "OK, now we have a template of what we want our predictions to look like. We have populated that template with the mean of each feature. Now let's use scikit-learn to get the estimated theta values, MSE, and RMSE for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3b81b388-9d95-4796-9850-406ef19f296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.03516080084618688 RMSE = 0.18751213519713034\n"
     ]
    }
   ],
   "source": [
    "regr = LinearRegression().fit(features, target)\n",
    "fitted_vals = regr.predict(features)\n",
    "\n",
    "MSE = mean_squared_error(target, fitted_vals, squared = True)\n",
    "RMSE = mean_squared_error(target, fitted_vals, squared = False)\n",
    "print('MSE =', MSE, 'RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "200d5657-ce9f-46d7-ad14-aa5558f283bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_estimate(nr_rooms, students_per_classroom, by_river=False, high_confidence=True):\n",
    "    \n",
    "    # Configure property\n",
    "    property_stats[0][RM_IDX] = nr_rooms\n",
    "    property_stats[0][PTRATIO_IDX] = students_per_classroom\n",
    "    \n",
    "    if by_river:\n",
    "        property_stats[0][CHAS_IDX] = 1\n",
    "    else:\n",
    "        property_stats[0][CHAS_IDX] = 0\n",
    "    \n",
    "    # Make prediction\n",
    "    log_estimate = regr.predict(property_stats)[0][0]\n",
    "    \n",
    "    # Calc Range\n",
    "    # If high_confidence, we'll calculate the 95% prob one. Otherwise, the 68% one:\n",
    "    if high_confidence:\n",
    "        upper_bound = log_estimate + 2*RMSE\n",
    "        lower_bound = log_estimate - 2*RMSE\n",
    "        interval = 95\n",
    "    else:\n",
    "        upper_bound = log_estimate + RMSE\n",
    "        lower_bound = log_estimate - RMSE\n",
    "        interval = 68\n",
    "    \n",
    "    return log_estimate, upper_bound, lower_bound, interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f5eb33-9958-448c-b73f-06b1c7926bff",
   "metadata": {},
   "source": [
    "**Challenge:** Write the code that converts the log price estimate using 1970s prices as well as the upper and lower bounds to today's prices. Round to the nearest 1000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d64a2b98-f5f4-4eaa-b7ee-fcfed3317fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale factor = 27.514150943396224\n"
     ]
    }
   ],
   "source": [
    "# Taking inflation into account, taking today's median price from Zillow:\n",
    "ZILLOW_MEDIAN_PRICE_TODAY = 583.3\n",
    "SEVENTIES_MEDIAN_PRICE = np.median(boston_dataset.target)\n",
    "scale_factor = ZILLOW_MEDIAN_PRICE_TODAY / SEVENTIES_MEDIAN_PRICE\n",
    "print('Scale factor =', scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "71720d9a-0d17-4b31-aed1-3f2a9c714906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dollar_estimate(rm, ptratio, chas=False, large_interval=True):\n",
    "\n",
    "    \"\"\"Estimate the price of a property in Boston.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    rm -- number of rooms in the property.\n",
    "    ptratio -- number of students per teacher in the classroom for the school in the area.\n",
    "    chas -- True if the property is next to the river, False otherwise.\n",
    "    large_range -- True for a 95% prediction interval, False for a 68% interval.\n",
    "    \n",
    "    Unrealistic inputs:\n",
    "    rm < 1\n",
    "    ptratio < 1 or ptratio > 50\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reject unrealistic values\n",
    "    if rm<1 or ptratio<1 or ptratio>50 :\n",
    "        print('This is unrealistic. Try again.')\n",
    "        return\n",
    "\n",
    "    log_est, upper, lower, conf = get_log_estimate(nr_rooms = rm, \n",
    "                                                   students_per_classroom = ptratio, \n",
    "                                                   by_river=chas, \n",
    "                                                   high_confidence=large_interval)\n",
    "\n",
    "    current_price_USD = round(np.e**log_est*1000*scale_factor,-3)\n",
    "    current_upper_USD = round(np.e**log_est*1000*scale_factor,-3)\n",
    "    current_lower_USD = round(np.e**log_est*1000*scale_factor,-3)\n",
    "    \n",
    "    print('Current estimated price in $:', current_price_USD)\n",
    "    print('1970s Upper bound in $:', current_upper_USD)\n",
    "    print('1970s Lower bound in $:', current_lower_USD)\n",
    "    print('Prediction\\'s confidence:', estimate[3], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e6b3003c-8621-45d6-8c61-b7fe58c9edfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is unrealistic. Try again.\n"
     ]
    }
   ],
   "source": [
    "# Price to estimate in log dollars:\n",
    "get_dollar_estimate(rm=2, ptratio=51, chas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da180e-845f-436f-b486-0893f47f172f",
   "metadata": {},
   "source": [
    "We now created a module from this code (called boston_valuation.py, stored in this same folder). Now we can call the module from any of our notebook in this same folder, by importing the module and calling the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bbb9db06-78f3-476f-baab-b329ab7c86a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boston_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/2880369080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mboston_valuation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dollar_estimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ML-bootcamp/Predict House Prices with Multivariable Linear Regression/boston_valuation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Scaling factor taking inflation into account\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mBOSTON_MEDIAN_PRICE_TODAY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m583.3\u001b[0m \u001b[0;31m# source: Zillow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mSEVENTIES_MEDIAN_PRICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboston_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mscale_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBOSTON_MEDIAN_PRICE_TODAY\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mSEVENTIES_MEDIAN_PRICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scale factor ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'boston_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import boston_valuation as val\n",
    "val.get_dollar_estimate(6, 12, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
